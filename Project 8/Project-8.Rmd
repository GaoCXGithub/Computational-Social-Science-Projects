---
title: "Project 8"
output:
  html_document:
    df_print: paged
---

```{r}
# Add to this package list for additional SL algorithms
pacman::p_load(
  tidyverse,
  ggthemes,
  ltmle,
  tmle,
  SuperLearner,
  tidymodels,
  caret,
  dagitty,
  ggdag,
  here,
  xgboost,
  randomForest)

heart_disease <- read_csv(here('Project 8', 'heart_disease_tmle.csv'))
```

# Introduction

Heart disease is the leading cause of death in the United States, and treating it properly is an important public health goal. However, it is a complex disease with several different risk factors and potential treatments. Physicians typically recommend changes in diet, increased exercise, and/or medication to treat symptoms, but it is difficult to determine how effective any one of these factors is in treating the disease. In this project, you will explore SuperLearner, Targeted Maximum Likelihood Estimation (TMLE), and Longitudinal Targeted Maximum Likelihood Estimation (LTMLE). Using a simulated dataset, you will explore whether taking blood pressure medication reduces mortality risk. 

# Data

This dataset was simulated using R (so it does not come from a previous study or other data source). It contains several variables:

\begin{itemize}
    \item \textbf{blood\_pressure\_medication}: Treatment indicator for whether the individual took blood pressure medication (0 for control, 1 for treatment)
    \item \textbf{mortality}: Outcome indicator for whether the individual passed away from complications of heart disease (0 for no, 1 for yes)
    \item \textbf{age}: Age at time 1
    \item \textbf{sex\_at\_birth}: Sex assigned at birth (0 female, 1 male)
    \item \textbf{simplified\_race}: Simplified racial category. (1: White/Caucasian, 2: Black/African American, 3: Latinx, 4: Asian American, \newline 5: Mixed Race/Other)
    \item \textbf{income\_thousands}: Household income in thousands of dollars
    \item \textbf{college\_educ}: Indicator for college education (0 for no, 1 for yes)
    \item \textbf{bmi}: Body mass index (BMI)
    \item \textbf{chol}: Cholesterol level
    \item \textbf{blood\_pressure}: Systolic blood pressure 
    \item \textbf{bmi\_2}: BMI measured at time 2
    \item \textbf{chol\_2}: Cholesterol measured at time 2
    \item \textbf{blood\_pressure\_2}: BP measured at time 2
    \item \textbf{blood\_pressure\_medication\_2}: Whether the person took treatment at time period 2 
\end{itemize}

For the "SuperLearner" and "TMLE" portions, you can ignore any variable that ends in "\_2", we will reintroduce these for LTMLE.

# SuperLearner

## Modeling

Fit a SuperLearner model to estimate the probability of someone dying from complications of heart disease, conditional on treatment and the relevant covariates. Do the following:

\begin{enumerate}
    \item Choose a library of at least 5 machine learning algorithms to evaluate. \textbf{Note}: We did not cover how to hyperparameter tune constituent algorithms within SuperLearner in lab, but you are free to do so if you like (though not required to for this exercise). 
    \item Split your data into train and test sets.
    \item Train SuperLearner
    \item Report the risk and coefficient associated with each model, and the performance of the discrete winner and SuperLearner ensemble
    \item Create a confusion matrix and report your overall accuracy, recall, and precision
\end{enumerate}

```{r}
# Fit SuperLearner Model

## sl lib
sl_libs <- c("SL.mean",
             "SL.glmnet", 
             "SL.glm",
             "SL.xgboost",
             "SL.randomForest",
             "SL.nnet")
```

mean: baseline model

GLM (Generalized Linear Model): A flexible extension of linear regression that allows for response variables with error distribution models other than a normal distribution.

GLMNet: A regularized version of GLM that applies penalties (such as Lasso or Ridge) to shrink coefficients or set them to zero, helping to prevent overfitting.

XGBoost: An ensemble learning method that builds decision trees sequentially. Each new tree is trained to predict the residual errors of the previous one using gradient descent. This method often achieves strong predictive performance.

Random Forest: An ensemble method that constructs multiple decision trees using bootstrap samples of the data and random subsets of features. This approach reduces overfitting and improves generalization by averaging the outputs of many de-correlated trees.

NNET (Neural Network): A model that adjusts its internal weights and biases by calculating the error between predicted and actual outputs. Each parameter’s contribution to the error is assessed, and updates are made to minimize this error through backpropagation.

Overall Objective: To build a diverse ensemble of models that leverages the “wisdom of crowds.” By combining models with different strengths and error patterns, their individual weaknesses may cancel out, leading to improved performance through a better bias-variance tradeoff.


```{r}
#preprocess: scaling
num_vars <- heart_disease %>% select(-sex_at_birth,
                                     -simplified_race,
                                     -college_educ,
                                     -blood_pressure_medication,
                                     -blood_pressure_medication_2,
                                     -mortality)

num_vars_scaled <- num_vars %>%
  mutate(across(everything(), ~ scale(.) %>% as.numeric()))

heart_disease_scaled <- heart_disease %>% 
  select(sex_at_birth, simplified_race, college_educ,
         blood_pressure_medication, blood_pressure_medication_2,mortality) %>%
  bind_cols(num_vars_scaled)

heart_disease_scaled_t0 <- heart_disease_scaled %>% select(-bmi_2,
                                                           -blood_pressure_2,
                                                           -chol_2,
                                                           -blood_pressure_medication_2)
```


```{r}
## Train/Test split
heart_d_split <- initial_split(heart_disease_scaled_t0,
                               prop = .75)

train <- training(heart_d_split)
test <- testing(heart_d_split)

y_train <- train %>% pull(mortality)
x_train <- train %>% select(-mortality)


y_test <- test %>% pull(mortality)
x_test <- test %>% select(-mortality)
```


```{r}
## Train SuperLearner
## Risk and Coefficient of each model

set.seed(42)
SL_ensamble <- SuperLearner(X = x_train,
                            Y = y_train,
                            SL.library = sl_libs,
                            family = binomial())
SL_ensamble
```
The Random Forest and Neural Network models contribute the most to the overall ensemble learner. Surprisingly, the weight assigned to XGBoost is zero, and its predictive error (risk) exceeds that of the baseline model. This may be due to the fact that XGBoost’s default hyperparameters are overly aggressive and poorly suited for small, simple datasets. Specifically:
	•	It converges too quickly to the training data, lacking sufficient regularization.
	•	The trees are excessively deep, leading to overfitting by capturing noise.
	•	As a result, its performance during cross-validation is worse than that of naive models, such as the simple average (SL.mean).

```{r}
## Discrete winner and superlearner ensemble performance
# ensemble
preds_en <- predict(SL_ensamble,
                 x_test,
                 onlySL = TRUE)$pred
preds_en_class <- ifelse(preds_en >= .5, 1, 0)
```

```{r}
## Confusion Matrix
library(caret)
library(yardstick)

confusionMatrix(factor(preds_en_class),
                factor(y_test),
                positive = "1")

tibble(truth = factor(y_test),
       prediction = factor(preds_en_class)) %>%
  conf_mat(truth, prediction) %>%
  autoplot(type = "heatmap")
```


```{r}
#winner
set.seed(42)
SL_nn <- SuperLearner(X = x_train,
                            Y = y_train,
                            SL.library = "SL.nnet",
                            family = binomial())

preds_nn <- predict(SL_nn,
                 x_test,
                 onlySL = TRUE)$pred
preds_nn_class <- ifelse(preds_nn >= .5, 1, 0)


confusionMatrix(factor(preds_nn_class),
                factor(y_test),
                positive = "1")

tibble(truth = factor(y_test),
       prediction = factor(preds_nn_class)) %>%
  conf_mat(truth, prediction) %>%
  autoplot(type = "heatmap")
```




```{r}
library(pROC)

roc_ens <- roc(y_test, preds_en_class)
plot(roc_ens, col = "steelblue", main = "ROC Curve")

roc_rf <- roc(y_test, preds_nn_class)
lines(roc_rf, col = "brown4")

legend("bottomright", legend = c("Ensemble", "Neural Net"),
       col = c("steelblue", "brown4"), lwd = 2)
```



## Discussion Questions

\begin{enumerate}
    \item Why should we, in general, prefer the SuperLearner ensemble to the discrete winner in cross-validation? Or in other words, what is the advantage of "blending" algorithms together and giving them each weights, rather than just using the single best algorithm (with best being defined as minimizing risk)?
\end{enumerate}

The comparison between the ensemble model and the standalone neural network model highlights that accuracy is not the sole optimization criterion for the Super Learner. While the ensemble model shows slightly lower overall accuracy—particularly noticeable in the ROC curve—its precision is higher, resulting in fewer false positives.

This distinction is important because, in Targeted Maximum Likelihood Estimation (TMLE), the Super Learner is used to estimate both the outcome model and the propensity score (i.e., the probability of receiving treatment). The goal of TMLE is to estimate the causal parameter of interest—such as the average treatment effect—as accurately and efficiently as possible, minimizing bias. The Super Learner serves as a flexible and robust component for estimating these intermediate models. The quality of its estimation is ultimately judged by its impact on the bias and variance of the resulting causal effect estimate.




# Targeted Maximum Likelihood Estimation

## Causal Diagram

TMLE requires estimating two models:

\begin{enumerate}
    \item The outcome model, or the relationship between the outcome and the treatment/predictors, $P(Y|(A,W)$.
    \item The propensity score model, or the relationship between assignment to treatment and predictors $P(A|W)$
\end{enumerate}

Using ggdag and daggity, draw a directed acylcic graph (DAG) that describes the relationships between the outcome, treatment, and covariates/predictors. Note, if you think there are covariates that are not related to other variables in the dataset, note this by either including them as freestanding nodes or by omitting them and noting omissions in your discussion.

```{r}
# DAG for TMLE
dag_t0 <- dagify(
  mortality ~ medication + health_var,
  medication ~ demographic_var + health_var,
  health_var ~ demographic_var,
  exposure = "medication",
  outcome = "mortality"
)


dag_data <- tidy_dagitty(dag_t0) %>%
  mutate(role = case_when(
    name == "medication" ~ "Exposure",
    name == "mortality" ~ "Outcome",
    TRUE ~ "Confounder"
  ))


ggdag(dag_data) +
  geom_dag_point(aes(fill = role), shape = 21, size = 16, color = "black") + 
  geom_dag_label_repel(aes(label = name), fontface = "bold", fill = "white", color = "black", size = 4) +  
  scale_fill_manual(values = c(
    "Exposure" = "darkred",
    "Outcome" = "navy",
    "Confounder" = "darkgrey"
  )) +
  labs(fill = "Node Role") +
  theme_void(base_size = 14) + 
  theme(
    legend.position = "right",
    plot.background = element_rect(fill = "white", color = NA)
  )
```

Confounders in this context can be broadly categorized into two groups: demographic variables and health status indicators. Demographic variables include sex assigned at birth, race, education level, age, and income. Health status encompasses factors such as body mass index (BMI), blood pressure, and cholesterol levels.
Health status directly influences the likelihood of developing heart disease and, consequently, affects mortality. It also plays a role in treatment decisions—for example, individuals with high blood pressure are more likely to be prescribed medication.
In contrast, demographic variables influence health status through pathways such as age-, gender-, and race-specific lifestyles. They also affect access to healthcare and the affordability of medication.
Importantly, we assume that the association between demographic variables and heart disease mortality is fully mediated by health status and medication use.

## TMLE Estimation

Use the `tmle` package to estimate a model for the effect of blood pressure medication on the probability of mortality. Do the following:

\begin{enumerate}
    \item Use the same SuperLearner library you defined earlier
    \item Use the same outcome model and propensity score model that you specified in the DAG above. If in your DAG you concluded that it is not possible to make a causal inference from this dataset, specify a simpler model and note your assumptions for this step.
    \item Report the average treatment effect and any other relevant statistics
\end{enumerate}

use both demographic variables and health status variables as covariates:

```{r}
set.seed(42)

Y <- heart_disease_scaled_t0$mortality
A <- heart_disease_scaled_t0$blood_pressure_medication
baseline_cov <- heart_disease_scaled_t0 %>% select(-mortality, 
                                                   -blood_pressure_medication)
tmle_fit <-
  tmle::tmle(Y = Y,                  # outcome
             A = A,                  # treatment
             W = baseline_cov, 
             Q.SL.library = sl_libs, # libraries for initial estimate 
             g.SL.library = sl_libs) # libraries for prob to be in treatment

# view results 
tmle_fit
```

TMLE estimation shows taking blood pressure medication significantly decreases death rate from complications of heart disease for about 37% percent. 

## Discussion Questions

\begin{enumerate}
    \item What is a "double robust" estimator? Why does it provide a guarantee of consistency if either the outcome model or propensity score model is correctly specified? Or in other words, why does mispecifying one of the models not break the analysis? \textbf{Hint}: When answering this question, think about how your introductory statistics courses emphasized using theory to determine the correct outcome model, and in this course how we explored the benefits of matching.
\end{enumerate}

The double robust estimator combines an outcome model and a treatment model (typically a propensity score model), offering a key advantage: as long as either model is correctly specified, the estimator can still produce unbiased estimates of causal effects.

In traditional statistical models, misspecification can arise from omitted variable bias or incorrect functional form. When a relevant covariate is omitted, its influence may be incorrectly attributed to other variables, leading to misleading causal or correlational conclusions. Similarly, if the functional form is incorrectly specified, the model may fail to capture the true relationship across the range of the data. Including irrelevant covariates, on the other hand, does not typically bias coefficient estimates but does increase variance, reducing efficiency.

The double robust approach mitigates these issues. If one model is correctly specified, it can compensate for the bias introduced by the misspecified model.
The outcome model predicts an individual’s potential outcome based on covariates, independently of treatment assignment. In an ideal case, it provides accurate counterfactual outcomes for treated units. Thus, the average difference between the predicted (counterfactual) and observed outcomes in the treatment group represents the causal effect. In this scenario, even if the propensity score model is misspecified, the causal effect can still be estimated accurately because the counterfactual outcomes are known.
Conversely, the propensity score model estimates the probability of receiving treatment given a set of covariates. A well-specified propensity model effectively balances covariates between treated and control groups, creating a pseudo-randomized comparison. When covariate balance is achieved, the difference in outcomes between the two groups can be attributed to the treatment effect. In this case, even if the outcome model is misspecified, the causal inference remains valid because the comparison is made between statistically equivalent groups—eliminating the need for an accurate prediction of outcomes.

This dual protection—requiring only one correctly specified model—makes the double robust estimator a powerful and flexible tool in causal inference.



# LTMLE Estimation

Now imagine that everything you measured up until now was in "time period 1". Some people either choose not to or otherwise lack access to medication in that time period, but do start taking the medication in time period 2. Imagine we measure covariates like BMI, blood pressure, and cholesterol at that time for everyone in the study (indicated by a "_2" after the covariate name). 

## Causal Diagram

Update your causal diagram to incorporate this new information. \textbf{Note}: If your groups divides up sections and someone is working on LTMLE separately from TMLE then just draw a causal diagram even if it does not match the one you specified above.

\textbf{Hint}: Check out slide 27 from Maya's lecture, or slides 15-17 from Dave's second slide deck in week 8 on matching.

\textbf{Hint}: Keep in mind that any of the variables that end in "\_2" are likely affected by both the previous covariates and the first treatment when drawing your DAG.

```{r}
# DAG for TMLE
dag_t1 <- dagify(
  mortality ~ medication_t1 + health_var_t1 + health_var_t0,
  medication_t1 ~ demographic_var + health_var_t1 + medication_t0,
  health_var_t1 ~ demographic_var + health_var_t0 + medication_t1 + medication_t0,
  medication_t0 ~ demographic_var + health_var_t0,
  exposure = c("medication_t1","medication_t0") ,
  outcome = "mortality"
)


dag_data <- tidy_dagitty(dag_t1) %>%
  mutate(role = case_when(
    name == "medication_t1" ~ "Exposure",
    name == "mortality" ~ "Outcome",
    TRUE ~ "Confounder"
  ))


ggdag(dag_data) +
  geom_dag_point(aes(fill = role), shape = 21, size = 16, color = "black") + 
  geom_dag_label_repel(aes(label = name), fontface = "bold", fill = "white", color = "black", size = 4) +  
  scale_fill_manual(values = c(
    "Exposure" = "darkred",
    "Outcome" = "navy",
    "Confounder" = "darkgrey"
  )) +
  labs(fill = "Node Role") +
  theme_void(base_size = 14) + 
  theme(
    legend.position = "right",
    plot.background = element_rect(fill = "white", color = NA)
  )

```

In a two-stage treatment model, the treatment administered in the first stage becomes a potential confounder for the second-stage treatment. Specifically, medication at time point t_0 can influence the second stage through three primary pathways: (1) it may have a direct effect on the outcome (e.g., mortality); (2) it can alter health status at time point t_1, as treatment effects from t_0 may persist over time; and (3) it may influence the likelihood of receiving treatment at t_1, potentially through behavioral factors such as adherence or habit formation.
For the purposes of this analysis, I assume that first-stage medication affects only blood pressure among all health status variables observed at the second stage.

## LTMLE Estimation

Use the `ltmle` package for this section. First fit a "naive model" that \textbf{does not} control for the time-dependent confounding. Then run a LTMLE model that does control for any time dependent confounding. Follow the same steps as in the TMLE section. Do you see a difference between the two estimates?

```{r}
A_vars <- c("blood_pressure_medication", "blood_pressure_medication_2")
Y_var <- "mortality"
W_demo_vars <- c("sex_at_birth", "simplified_race", "college_educ", "age", "income_thousands")
W_health_vars <- c("bmi", "blood_pressure", "chol","bmi_2", "chol_2")
L_timedep_vars <- "blood_pressure_2"

W_baseline_vars <- c(W_demo_vars, W_health_vars)
L_all_vars <- c("blood_pressure_2")
```

```{r}
col_order <- c(
  W_baseline_vars,
  A_vars[1],
  L_timedep_vars,
  A_vars[2],
  Y_var)

heart_disease_scaled_ordered <- heart_disease_scaled[, col_order]
```



```{r}
## Naive Model (no time-dependent confounding) estimate
set.seed(42)

naive_data_subset <- heart_disease_scaled_ordered[, !(names(heart_disease_scaled_ordered) %in% L_timedep_vars)]

ltmle_fit_naive <- ltmle(data = naive_data_subset,
                         Anodes = A_vars,
                         Lnodes = W_baseline_vars, 
                         Ynodes = Y_var,
                         abar = list(treatment = c(1,1), control = c(0,0)),
                         SL.library = sl_libs,
                         survivalOutcome = FALSE)

summary_ltmle_naive <- summary(ltmle_fit_naive)
print(summary_ltmle_naive)
```




```{r, warning=FALSE}
## LTMLE estimate
set.seed(42)

ltmle_fit <- ltmle(data = heart_disease_scaled_ordered,
                         Anodes = A_vars,
                         Lnodes = "blood_pressure_2", 
                         Ynodes = Y_var,
                         abar = list(treatment = c(1,1), control = c(0,0)),
                         SL.library = sl_libs,
                         survivalOutcome = FALSE)

summary_ltmle <- summary(ltmle_fit)
print(summary_ltmle)
```

## Discussion Questions

\begin{enumerate}
    \item What sorts of time-dependent confounding should we be especially worried about? For instance, would we be concerned about a running variable for age the same way we might be concerned about blood pressure measured at two different times?
\end{enumerate}

Age and blood pressure, though both time-dependent variables measured at multiple time points, represent fundamentally different categories of time-varying confounders.

Age is a time-varying confounder that evolves deterministically over time and is independent of prior treatment. While age may cross a critical threshold beyond which mortality risk increases sharply, this is not problematic if age is properly adjusted for in both baseline and time-updated models. In this case, its time-varying nature is reflected through changes in its estimated effect (i.e., coefficient), rather than through treatment-induced changes in its value.
In contrast, blood pressure is a time-dependent variable that can be affected by prior treatment. It changes both naturally, as a reflection of an individual’s evolving health status, and in response to interventions—such as medication administered in the first stage. Consequently, blood pressure embodies both confounding variation (as it influences both current treatment assignment and future outcomes) and treatment effects from earlier stages. Conditioning on such a variable introduces two key risks:
	1.	Confounding bias, because blood pressure serves as a common cause of current treatment and outcome.
	2.	Bias from blocking causal pathways, because conditioning on blood pressure—partly a result of prior treatment—can obscure the true effect of that earlier treatment by artificially closing part of the causal chain.

This complexity is precisely what Longitudinal Targeted Maximum Likelihood Estimation (LTMLE) is designed to handle. At its core, LTMLE implements the logic of the G-formula, constructing a sequence of outcome models (Q-models) from the final time point backward. These models estimate the expected outcome under specific histories of treatment and covariates, effectively capturing and adjusting for the dual role of variables like blood pressure—simultaneously mediators of past treatment effects and confounders of future treatment-outcome relationships.

The propensity score model (or treatment mechanism model) plays a critical role in LTMLE’s targeting step. It helps calibrate or “target” the initial Q-model estimates, improving the accuracy and robustness of the final causal effect estimate. This model quantifies, at each time point, the probability of receiving treatment given an individual’s covariate and treatment history (including prior blood pressure and treatment). Accurately modeling these probabilities is essential for understanding the natural treatment assignment process, which is a prerequisite for making valid comparisons to hypothetical interventions.



