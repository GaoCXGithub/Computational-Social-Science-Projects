abs(standardized_diff[valid_indices]) * 100
mean_pct_improvement <- mean(pct_improvements, na.rm = TRUE)
}
}
prop_balanced <- mean(abs(standardized_diff) < 0.1, na.rm = TRUE)
# 根据是否需要保存详细模型返回不同的结果
if (save_full_model) {
return(list(att = att,
prop_balanced = prop_balanced,
mean_pct_improvement = mean_pct_improvement,
match_obj = matchout,
genout = genout,
covs_used = ps_covs,
n_covs = length(ps_covs),
pre_std_diff = standardized_diff,
post_std_diff = post_standardized_diff))
} else {
return(list(att = att,
prop_balanced = prop_balanced,
mean_pct_improvement = NA,
covs_used = ps_covs,
n_covs = length(ps_covs)))
}
}
set.seed(42)
n_sims <- 10000
chunk_size <- 2500
n_chunks <- ceiling(n_sims / chunk_size)
selected_model_indices <- sample(1:n_sims, 10)
detailed_models <- vector("list", 10)
results_list <- vector("list", n_chunks)
for (chunk_i in seq_len(n_chunks)) {
start_idx <- (chunk_i - 1) * chunk_size + 1
end_idx   <- min(chunk_i * chunk_size, n_sims)
indices   <- start_idx:end_idx
block_results <- vector("list", length(indices))
for (j in seq_along(indices)) {
sim_index <- indices[j]
if (j %% 500 == 0) {
cat(sim_index, "/10000 \n")
}
# Run the standard simulation
gen_result <- run_genetic_simulation(
data = ypsps,
treatment = "college",
outcome = "student_ppnscal",
baseline_covs = baseline_cov_list,
post_covs = post_cov_list
)
# Store the basic result
block_results[[j]] <- gen_result
# If this is one of our pre-selected indices, store the detailed model
if (sim_index %in% selected_model_indices) {
# Run the simulation again, but this time keep the full ps_model
detailed_model <- run_genetic_simulation(
data = ypsps,
treatment = "college",
outcome = "student_ppnscal",
baseline_covs = baseline_cov_list,
post_covs = post_cov_list
)
# Run matchit again with the same covariates to get the ps_model
ps_formula <- as.formula(paste("college ~", paste(result$covs_used, collapse = " + ")))
ps_match <- try(matchit(ps_formula,
data = ypsps,
method = "nearest",
distance = "logit",
replace = TRUE,
ratio = 1),
silent = TRUE)
# Store the ps_model in our detailed models list
gen_detailed_model$ps_model <- ps_match
gen_detailed_model$sim_index <- sim_index
gen_detailed_models[[which(selected_model_indices == sim_index)]] <- gen_detailed_model
}
}
block_df <- do.call(rbind, lapply(seq_along(block_results), function(j) {
res <- block_results[[j]]
data.frame(
sim_id = indices[j],
att = res$att,
prop_balanced = res$prop_balanced,
mean_pct_improvement = res$mean_pct_improvement,
n_covs = res$n_covs,
stringsAsFactors = FALSE
)
}))
block_df <- block_df[!is.na(block_df$att), ]
results_list[[chunk_i]] <- block_df
rm(block_results, block_df)
gc()
}
library(Matching)
run_genetic_simulation <- function(data, treatment, outcome,
baseline_covs, post_covs,
save_full_model = FALSE,
random_seed = NULL) {
if (!is.null(random_seed)) set.seed(random_seed)
valid_baseline_covs <- baseline_covs[!(baseline_covs %in% c(treatment, outcome))]
valid_baseline_covs <- Filter(function(var) {
if (!var %in% names(data)) return(FALSE)
if (length(unique(data[[var]])) <= 1) return(FALSE)
TRUE
}, valid_baseline_covs)
if (length(valid_baseline_covs) == 0) {
warning("No available covariates")
return(list(att = NA, prop_balanced = NA, mean_pct_improvement = NA,
covs_used = NA, n_covs = 0))
}
n_covs <- sample(1:length(valid_baseline_covs), 1)
ps_covs <- sample(valid_baseline_covs, n_covs)
X <- as.matrix(data[, ps_covs, drop = FALSE])
X <- apply(X, 2, function(x) {
if (is.factor(x) || is.character(x)) {
as.numeric(as.factor(x))
} else {
x
}
})
genout <- try(GenMatch(Tr = data[[treatment]],
X = X,
BalanceMatrix = X,
estimand = "ATT",
pop.size = 10,
max.generations = 5,
wait.generations = 2,
print.level = 0),
silent = TRUE)
if (inherits(genout, "try-error")) {
return(list(att = NA, prop_balanced = NA, mean_pct_improvement = NA,
covs_used = ps_covs, n_covs = length(ps_covs)))
}
matchout <- try(Match(Tr = data[[treatment]],
X = X,
Weight.matrix = genout,
estimand = "ATT",
M = 1,
replace = TRUE),
silent = TRUE)
if (inherits(matchout, "try-error")) {
return(list(att = NA, prop_balanced = NA, mean_pct_improvement = NA,
covs_used = ps_covs, n_covs = length(ps_covs)))
}
att <- matchout$est
# 计算标准化差异
standardized_diff <- sapply(ps_covs, function(var) {
tr_vals <- data[data[[treatment]] == 1, var]
co_vals <- data[data[[treatment]] == 0, var]
diff_val <- mean(tr_vals, na.rm = TRUE) - mean(co_vals, na.rm = TRUE)
pooled_sd <- sqrt((var(tr_vals, na.rm = TRUE) + var(co_vals, na.rm = TRUE)) / 2)
if (pooled_sd == 0) return(NA) else return(diff_val / pooled_sd)
})
# 仅当需要保存完整模型时才计算后匹配标准化差异
post_standardized_diff <- NULL
mean_pct_improvement <- NA
if (save_full_model) {
# 获取匹配样本的索引
matched_indices_treated <- matchout$index.treated
matched_indices_control <- matchout$index.control
# 计算匹配后的标准化差异
post_standardized_diff <- sapply(ps_covs, function(var) {
tr_vals <- data[matched_indices_treated, var]
co_vals <- data[matched_indices_control, var]
diff_val <- mean(tr_vals, na.rm = TRUE) - mean(co_vals, na.rm = TRUE)
pooled_sd <- sqrt((var(tr_vals, na.rm = TRUE) + var(co_vals, na.rm = TRUE)) / 2)
if (pooled_sd == 0) return(NA) else return(diff_val / pooled_sd)
})
# 计算改进百分比（仅对非零、非NA的差异）
valid_indices <- !is.na(standardized_diff) & !is.na(post_standardized_diff) &
standardized_diff != 0
if (any(valid_indices)) {
pct_improvements <- (standardized_diff[valid_indices] -
post_standardized_diff[valid_indices]) /
abs(standardized_diff[valid_indices]) * 100
mean_pct_improvement <- mean(pct_improvements, na.rm = TRUE)
}
}
prop_balanced <- mean(abs(standardized_diff) < 0.1, na.rm = TRUE)
# 根据是否需要保存详细模型返回不同的结果
if (save_full_model) {
return(list(att = att,
prop_balanced = prop_balanced,
mean_pct_improvement = mean_pct_improvement,
match_obj = matchout,
genout = genout,
covs_used = ps_covs,
n_covs = length(ps_covs),
pre_std_diff = standardized_diff,
post_std_diff = post_standardized_diff))
} else {
return(list(att = att,
prop_balanced = prop_balanced,
mean_pct_improvement = NA,
covs_used = ps_covs,
n_covs = length(ps_covs)))
}
}
# Load tidyverse and MatchIt
# Feel free to load other libraries as you wish
library(tidyverse)
library(MatchIt)
suppressWarnings({
log(-1)
})
library(cobalt)
# Load ypsps data
ypsps <- read_csv('data/ypsps.csv')
head(ypsps)
# Generate a vector that randomly assigns each unit to treatment/control
set.seed(42)
test_ypsps <- ypsps %>% mutate(random_treat = sample(0:1,nrow(ypsps), replace = TRUE))
# Choose a baseline covariate (use dplyr for this)
test_ypsps <- test_ypsps %>% select(random_treat, parent_Vote)
# Visualize the distribution by treatment/control (ggplot)
balance_plot <- ggplot(test_ypsps,
aes(x = factor(random_treat), fill = factor(parent_Vote))) +
geom_bar(position = "fill") +
theme_bw() +
theme(legend.position = "bottom") +
scale_fill_manual(values = c("red","steelblue")) +
scale_y_continuous(labels = scales::percent_format()) +
labs(
x = "Treatment assignment (0=Control, 1=Treatment)",
y = "Proportion",
fill = "Parent Vote (0=No, 1=Yes)",
title = "Distribution of Covariate with Randomized Treatment Assignment"
)
print(balance_plot)
treatment_prop <- test_ypsps %>%
filter(random_treat == 1) %>%
summarize(prop_vote = mean(parent_Vote)) %>%
pull()
control_prop <- test_ypsps %>%
filter(random_treat == 0) %>%
summarize(prop_vote = mean(parent_Vote)) %>%
pull()
imbalance <- treatment_prop - control_prop
chisq <- chisq.test(table(test_ypsps$random_treat, test_ypsps$parent_Vote))
cat("Imbalance in covariate between treatment and control:", imbalance, "\n")
cat("Chi-square statistic:", chisq$statistic, "\n")
cat("Chi-square p-value:", chisq$p.value, "\n")
# Simulate this 10,000 times (monte carlo simulation - see R Refresher for a hint)
set.seed(42)
simulate_randomization <- function(data, iterations = 10000) {
results <- map_dbl(1:iterations, function(i) {
random_assign <- sample(0:1, nrow(data), replace = TRUE)
treat_prop <- mean(data$parent_Vote[random_assign == 1])
ctrl_prop <- mean(data$parent_Vote[random_assign == 0])
return(treat_prop - ctrl_prop)
})
return(results)
}
imbalance_distribution <- simulate_randomization(ypsps)
# Visualize the distribution of imbalances
imbalance_plot <- ggplot(data.frame(imbalance = imbalance_distribution), aes(x = imbalance)) +
geom_histogram(bins = 50, fill = "steelblue", color = "black") +
geom_vline(xintercept = 0, color = "red", linetype = "dashed") +
labs(title = "Distribution of Treatment-Control Imbalances in Covariate: parent_Vote",
x = "Imbalance (Treatment Proportion - Control Proportion)",
y = "Frequency") +
theme_minimal()
print(imbalance_plot)
significant_imbalance <- mean(abs(imbalance_distribution) > 0.05)
cat("Proportion of randomizations with imbalance > 0.05:", significant_imbalance, "\n")
cat("Mean of imbalances:", mean(imbalance_distribution), "\n")
cat("Standard deviation of imbalances:", sd(imbalance_distribution), "\n")
cat("95% range of imbalances:", quantile(imbalance_distribution, c(0.025, 0.975)), "\n")
# Select covariates that represent the "true" model for selection, fit model
# covariates selection
post_cov_list <- c(names(ypsps[123:162])) #placebo and variables recorded in 1982 are exclueded
invalid_post_covs <- c("student_1973CollegeDegree",
"student_1973CurrentCollege",
"student_1973CollegeYears")
post_cov_list <- setdiff(post_cov_list, invalid_post_covs)
baseline_cov_list <- c(names(ypsps[12:120]))
student_ext_efficacy <- c ("student_GovtOpinion", "student_GovtCrook", "student_GovtWaste",
"student_TrGovt", "student_GovtSmart", "student_Govt4All")
parent_ext_efficacy <- c ("parent_GovtOpinion", "parent_GovtCrook", "parent_GovtWaste",
"parent_TrGovt", "parent_GovtSmart", "parent_Govt4All")
student_personality <- c("student_Cynic", "student_LifeWish", "student_GLuck", "student_FPlans",
"student_EgoA", "student_WinArg", "student_StrOpinion", "student_MChange",
"student_EgoB","student_TrOthers","student_OthHelp","student_OthFair",
"student_Trust")
parent_personality <- c("parent_Cynic", "parent_LifeWish", "parent_GLuck", "parent_FPlans",
"parent_EgoA", "parent_WinArg", "parent_StrOpinion", "parent_MChange",
"parent_EgoB","parent_TrOthers","parent_OthHelp","parent_OthFair",
"parent_Trust")
excluded <- c (student_ext_efficacy, parent_ext_efficacy,
student_personality, parent_personality)
cov_selected <- baseline_cov_list[!baseline_cov_list %in% excluded]
# Fit model
true_model <- ypsps %>% select(college,
student_ppnscal,
all_of(cov_selected),
all_of(post_cov_list))
formula_str <- paste("college ~", paste(cov_selected, collapse = " + "))
match_formula <- as.formula(formula_str)
match_result <- matchit(match_formula,
data = true_model,
method = "nearest",
distance = "logit")
summary(match_result)
# Plot the balance for the top 10 covariates
ps_model <- match_result$model
coef_vec <- coef(ps_model)
coef_vec <- coef_vec[names(coef_vec) != "(Intercept)"]
top10_names <- names(sort(abs(coef_vec), decreasing = TRUE))[1:10]
top10_df <- data.frame(
Variable = top10_names,
Coefficient = coef_vec[top10_names]
)
top10_df$Variable <- factor(top10_df$Variable, levels = top10_df$Variable[order(abs(top10_df$Coefficient))])
ggplot(top10_df, aes(x = Variable, y = Coefficient, fill = Coefficient > 0)) +
geom_col(show.legend = FALSE) +
coord_flip() +
scale_fill_manual(values = c("red", "steelblue")) +
labs(
title = "Top 10 Covariates Influencing Propensity Score",
y = "Logit Coefficient",
x = NULL
) +
theme_minimal() +
theme(axis.text = element_text(size = 12))
bal <- bal.tab(match_result, un = TRUE)
balance_df <- bal$Balance
balance_df$varname <- rownames(balance_df)
vars_to_plot <- intersect(top10_names, balance_df$varname)
top10_df <- balance_df[balance_df$varname %in% vars_to_plot, ]
plot_df <- top10_df %>%
select(varname, Diff.Un, Diff.Adj) %>%
pivot_longer(cols = c(Diff.Un, Diff.Adj),
names_to = "match_status",
values_to = "smd") %>%
mutate(match_status = recode(match_status,
"Diff.Un" = "Before Matching",
"Diff.Adj" = "After Matching"))
ggplot(plot_df, aes(x = smd, y = reorder(varname, abs(smd)), fill = match_status)) +
geom_col(position = position_dodge(width = 0.7), width = 0.6) +
labs(
title = "Standardized Mean Differences of Top 10 Covariates",
x = "Standardized Mean Difference",
y = "Covariates",
fill = ""
) +
theme_minimal(base_size = 13) +
theme(legend.position = "top")
# Report the overall balance and the proportion of covariates that meet the balance threshold
pscores <- match_result$distance
treat <- ypsps$college
weights <- match_result$weights
matched_df <- data.frame(
pscore = pscores,
treat = as.factor(treat),
weights = weights
) %>% filter(weights > 0)
ggplot(matched_df, aes(x = pscore, fill = treat)) +
geom_density(alpha = 0.5) +
labs(title = "Propensity Score Distribution After Matching",
x = "Propensity Score",
y = "Density",
fill = "Treatment Group") +
theme_minimal()
pscore_row <- bal$Balance["distance",]
print(pscore_row) # a failed matching
balance_df <- bal$Balance
balance_vars <- balance_df[!rownames(balance_df) %in% c("(Intercept)", "distance"), ]
num_balanced <- sum(abs(balance_vars$Diff.Adj) <= 0.1, na.rm = TRUE)
cat("Number of covariates with adjusted SMD ≤ 0.1:", num_balanced, "\n")
# Calculate ATT
matched_data <- match.data(match_result)
formula_str <- paste("student_ppnscal ~ college + ", paste(post_cov_list, collapse = " + "))
att_model <- lm(as.formula(formula_str),
data = matched_data,
weights = matched_data$weights)
summary(att_model)
run_ps_simulation <- function(data, treatment, outcome,
baseline_covs, post_covs) {
valid_baseline_covs <- baseline_covs[!(baseline_covs %in% c(treatment, outcome))]
valid_baseline_covs <- Filter(function(var) {
if (!var %in% names(data)) return(FALSE)
if (length(unique(data[[var]])) <= 1) return(FALSE)
TRUE
}, valid_baseline_covs)
if (length(valid_baseline_covs) == 0) {
warning("No available baseline covariates")
return(list(att = NA, prop_balanced = NA, mean_pct_improvement = NA,
covs_used = NA))
}
n_covs <- sample(1:length(valid_baseline_covs), 1)
ps_covs <- sample(valid_baseline_covs, n_covs)
ps_formula <- as.formula(paste(treatment, "~", paste(ps_covs, collapse = " + ")))
ps_match <- try(matchit(ps_formula,
data = data,
method = "nearest",
distance = "logit",
replace = TRUE,
ratio = 1),
silent = TRUE)
if (inherits(ps_match, "try-error")) {
return(list(att = NA, prop_balanced = NA, mean_pct_improvement = NA,
covs_used = ps_covs))
}
matched_data <- try(match.data(ps_match), silent = TRUE)
if (inherits(matched_data, "try-error") || nrow(matched_data) == 0) {
return(list(att = NA, prop_balanced = NA, mean_pct_improvement = NA,
covs_used = ps_covs))
}
valid_post_covs <- post_covs[!(post_covs %in% c(treatment, outcome))]
post_formula <- as.formula(
paste(outcome, "~", treatment,
if (length(valid_post_covs) > 0) paste("+", paste(valid_post_covs, collapse = " + ")) else "")
)
m <- try(lm(post_formula, data = matched_data, weights = matched_data$weights), silent = TRUE)
if (inherits(m, "try-error")) {
return(list(att = NA, prop_balanced = NA, mean_pct_improvement = NA,
covs_used = ps_covs))
}
att <- try(coef(m)[treatment], silent = TRUE)
if (inherits(att, "try-error") || is.na(att)) {
att <- NA
}
bal <- try(bal.tab(ps_match, un = TRUE, m.threshold = 0.1), silent = TRUE)
if (inherits(bal, "try-error")) {
return(list(att = att, prop_balanced = NA, mean_pct_improvement = NA,
covs_used = ps_covs))
}
smd_table <- bal$Balance
if ("M.Threshold.Adj" %in% names(smd_table)) {
prop_balanced <- mean(smd_table$M.Threshold.Adj, na.rm = TRUE)
} else {
prop_balanced <- mean(abs(smd_table$Diff.Adj) <= 0.1, na.rm = TRUE)
}
if (!any(is.na(smd_table$Diff.Un)) && !any(is.na(smd_table$Diff.Adj))) {
pct_improvements <- (smd_table$Diff.Un - smd_table$Diff.Adj) / smd_table$Diff.Un * 100
mean_pct_improvement <- mean(pct_improvements, na.rm = TRUE)
} else {
mean_pct_improvement <- NA
}
return(list(att = att,
prop_balanced = prop_balanced,
mean_pct_improvement = mean_pct_improvement,
n_covs = length(ps_covs),
covs_used = ps_covs))
}
n_sims <- 10000
chunk_size <- 2500
n_chunks <- ceiling(n_sims / chunk_size)
# Pre-select 10 random indices for which detailed model information will be stored
selected_model_indices <- sample(1:n_sims, 10)
detailed_models <- vector("list", 10)
results_list <- vector("list", n_chunks)
for (chunk_i in seq_len(n_chunks)) {
start_idx <- (chunk_i - 1) * chunk_size + 1
end_idx   <- min(chunk_i * chunk_size, n_sims)
indices   <- start_idx:end_idx
block_results <- vector("list", length(indices))
for (j in seq_along(indices)) {
sim_index <- indices[j]
if (j %% 500 == 0) {
cat(sim_index, "/10000 \n")
}
# Run the standard simulation
result <- run_ps_simulation(
data = ypsps,
treatment = "college",
outcome = "student_ppnscal",
baseline_covs = baseline_cov_list,
post_covs = post_cov_list
)
# Store the basic result
block_results[[j]] <- result
# If this is one of our pre-selected indices, store the detailed model
if (sim_index %in% selected_model_indices) {
# Run the simulation again, but this time keep the full ps_model
detailed_model <- run_ps_simulation(
data = ypsps,
treatment = "college",
outcome = "student_ppnscal",
baseline_covs = baseline_cov_list,
post_covs = post_cov_list
)
# Run matchit again with the same covariates to get the ps_model
ps_formula <- as.formula(paste("college ~", paste(result$covs_used, collapse = " + ")))
ps_match <- try(matchit(ps_formula,
data = ypsps,
method = "nearest",
distance = "logit",
replace = TRUE,
ratio = 1),
silent = TRUE)
# Store the ps_model in our detailed models list
detailed_model$ps_model <- ps_match
detailed_model$sim_index <- sim_index
detailed_models[[which(selected_model_indices == sim_index)]] <- detailed_model
}
}
block_df <- do.call(rbind, lapply(seq_along(block_results), function(j) {
res <- block_results[[j]]
data.frame(
sim_id = indices[j],
att = res$att,
prop_balanced = res$prop_balanced,
mean_pct_improvement = res$mean_pct_improvement,
n_covs = res$n_covs,
stringsAsFactors = FALSE
)
}))
block_df <- block_df[!is.na(block_df$att), ]
results_list[[chunk_i]] <- block_df
rm(block_results, block_df)
gc()
}
